{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:02.665455Z","iopub.status.busy":"2023-04-10T15:35:02.664557Z","iopub.status.idle":"2023-04-10T15:35:02.687951Z","shell.execute_reply":"2023-04-10T15:35:02.686379Z","shell.execute_reply.started":"2023-04-10T15:35:02.665418Z"},"trusted":true},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:02.691233Z","iopub.status.busy":"2023-04-10T15:35:02.690190Z","iopub.status.idle":"2023-04-10T15:35:02.792992Z","shell.execute_reply":"2023-04-10T15:35:02.791909Z","shell.execute_reply.started":"2023-04-10T15:35:02.691195Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('../data/train.csv')\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:02.795708Z","iopub.status.busy":"2023-04-10T15:35:02.794755Z","iopub.status.idle":"2023-04-10T15:35:02.852647Z","shell.execute_reply":"2023-04-10T15:35:02.851521Z","shell.execute_reply.started":"2023-04-10T15:35:02.795669Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>36473</td>\n","      <td>36473</td>\n","      <td>36473</td>\n","      <td>36473</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>36473</td>\n","      <td>733</td>\n","      <td>29340</td>\n","      <td>106</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>component composite coating</td>\n","      <td>composition</td>\n","      <td>H01</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>152</td>\n","      <td>24</td>\n","      <td>2186</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      id                       anchor       target context\n","count              36473                        36473        36473   36473\n","unique             36473                          733        29340     106\n","top     37d61fd2272659b1  component composite coating  composition     H01\n","freq                   1                          152           24    2186"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include='object')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:02.856003Z","iopub.status.busy":"2023-04-10T15:35:02.855536Z","iopub.status.idle":"2023-04-10T15:35:02.881947Z","shell.execute_reply":"2023-04-10T15:35:02.880853Z","shell.execute_reply.started":"2023-04-10T15:35:02.855953Z"},"trusted":true},"outputs":[],"source":["df['input'] = 'TEXT1: '+ df.context + '; TEXT2: ' + df.target + '; ANC1: ' + df.anchor"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:02.884192Z","iopub.status.busy":"2023-04-10T15:35:02.883768Z","iopub.status.idle":"2023-04-10T15:35:02.895754Z","shell.execute_reply":"2023-04-10T15:35:02.894432Z","shell.execute_reply.started":"2023-04-10T15:35:02.884153Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0    TEXT1: A47; TEXT2: abatement of pollution; ANC...\n","1    TEXT1: A47; TEXT2: act of abating; ANC1: abate...\n","2    TEXT1: A47; TEXT2: active catalyst; ANC1: abat...\n","3    TEXT1: A47; TEXT2: eliminating process; ANC1: ...\n","4    TEXT1: A47; TEXT2: forest region; ANC1: abatement\n","Name: input, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df['input'].head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:02.898085Z","iopub.status.busy":"2023-04-10T15:35:02.897166Z","iopub.status.idle":"2023-04-10T15:35:04.753290Z","shell.execute_reply":"2023-04-10T15:35:04.752059Z","shell.execute_reply.started":"2023-04-10T15:35:02.898043Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset, DatasetDict\n","# Tokenization: split each text up into words (tokens)\n","# Numericalization: convert each word (token) into number\n","# Transformers uses Dataset object for storing dataset! We can \n","# create one as follows\n","ds = Dataset.from_pandas(df)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:04.756132Z","iopub.status.busy":"2023-04-10T15:35:04.755148Z","iopub.status.idle":"2023-04-10T15:35:04.765508Z","shell.execute_reply":"2023-04-10T15:35:04.764042Z","shell.execute_reply.started":"2023-04-10T15:35:04.756093Z"},"trusted":true},"outputs":[],"source":["model_nm = 'microsoft/deberta-v3-small'"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:04.775373Z","iopub.status.busy":"2023-04-10T15:35:04.769101Z","iopub.status.idle":"2023-04-10T15:35:09.583054Z","shell.execute_reply":"2023-04-10T15:35:09.581986Z","shell.execute_reply.started":"2023-04-10T15:35:04.775333Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17518f476f0143a08d0f42151c462742","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dce5e2fb9bf846aea77fa0bbd055fc4f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62fa119d0b414bdbaf596178d08d17b2","version_major":2,"version_minor":0},"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","tokz = AutoTokenizer.from_pretrained(model_nm) # get the preprocessing "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:09.585845Z","iopub.status.busy":"2023-04-10T15:35:09.584735Z","iopub.status.idle":"2023-04-10T15:35:09.601228Z","shell.execute_reply":"2023-04-10T15:35:09.599663Z","shell.execute_reply.started":"2023-04-10T15:35:09.585811Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['▁TEXT',\n"," '1',\n"," ':',\n"," '▁A',\n"," '47',\n"," ';',\n"," '▁TEXT',\n"," '2',\n"," ':',\n"," '▁abatement',\n"," '▁of',\n"," '▁pollution',\n"," ';',\n"," '▁ANC',\n"," '1',\n"," ':',\n"," '▁abatement']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tokz.tokenize('TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:09.611408Z","iopub.status.busy":"2023-04-10T15:35:09.610663Z","iopub.status.idle":"2023-04-10T15:35:09.618396Z","shell.execute_reply":"2023-04-10T15:35:09.615367Z","shell.execute_reply.started":"2023-04-10T15:35:09.611362Z"},"trusted":true},"outputs":[],"source":["# turn token to number\n","def tok_func(x):\n","  return tokz(x['input']) # use the same preprocessing on out input data"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:09.625201Z","iopub.status.busy":"2023-04-10T15:35:09.622496Z","iopub.status.idle":"2023-04-10T15:35:12.104269Z","shell.execute_reply":"2023-04-10T15:35:12.103191Z","shell.execute_reply.started":"2023-04-10T15:35:09.625162Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"befa3b18fb644966a1e409d8eaf0455f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/37 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tok_ds= ds.map(tok_func, batched=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.106162Z","iopub.status.busy":"2023-04-10T15:35:12.105698Z","iopub.status.idle":"2023-04-10T15:35:12.113996Z","shell.execute_reply":"2023-04-10T15:35:12.112809Z","shell.execute_reply.started":"2023-04-10T15:35:12.106123Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('TEXT1: A47; TEXT2: abatement of pollution; ANC1: abatement',\n"," [1,\n","  54453,\n","  435,\n","  294,\n","  336,\n","  5753,\n","  346,\n","  54453,\n","  445,\n","  294,\n","  47284,\n","  265,\n","  6435,\n","  346,\n","  23702,\n","  435,\n","  294,\n","  47284,\n","  2])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["row = tok_ds[0]\n","row['input'], row['input_ids']"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.116112Z","iopub.status.busy":"2023-04-10T15:35:12.115630Z","iopub.status.idle":"2023-04-10T15:35:12.197449Z","shell.execute_reply":"2023-04-10T15:35:12.196306Z","shell.execute_reply.started":"2023-04-10T15:35:12.116076Z"},"trusted":true},"outputs":[{"data":{"text/plain":["265"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tokz.vocab['▁of']"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.199668Z","iopub.status.busy":"2023-04-10T15:35:12.199280Z","iopub.status.idle":"2023-04-10T15:35:12.207707Z","shell.execute_reply":"2023-04-10T15:35:12.206605Z","shell.execute_reply.started":"2023-04-10T15:35:12.199630Z"},"trusted":true},"outputs":[],"source":["tok_ds = tok_ds.rename_columns({'score':'labels'})"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.210129Z","iopub.status.busy":"2023-04-10T15:35:12.209176Z","iopub.status.idle":"2023-04-10T15:35:12.235009Z","shell.execute_reply":"2023-04-10T15:35:12.233928Z","shell.execute_reply.started":"2023-04-10T15:35:12.210069Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>36</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>36</td>\n","      <td>34</td>\n","      <td>36</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>4112d61851461f60</td>\n","      <td>el display</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      id      anchor                         target context\n","count                 36          36                             36      36\n","unique                36          34                             36      29\n","top     4112d61851461f60  el display  inorganic photoconductor drum     G02\n","freq                   1           2                              1       3"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Test and validation sets\n","eval_df = pd.read_csv('../data/test.csv')\n","eval_df.describe()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.236909Z","iopub.status.busy":"2023-04-10T15:35:12.236550Z","iopub.status.idle":"2023-04-10T15:35:12.254890Z","shell.execute_reply":"2023-04-10T15:35:12.254020Z","shell.execute_reply.started":"2023-04-10T15:35:12.236872Z"},"trusted":true},"outputs":[],"source":["# Transformers uses DatasetDict for holding training and validation set\n","# To create one that contain 25% validation and 75% training set user train_test_splt on Dataset\n","dds = tok_ds.train_test_split(0.25, seed=42)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.256657Z","iopub.status.busy":"2023-04-10T15:35:12.256297Z","iopub.status.idle":"2023-04-10T15:35:12.263367Z","shell.execute_reply":"2023-04-10T15:35:12.262354Z","shell.execute_reply.started":"2023-04-10T15:35:12.256622Z"},"trusted":true},"outputs":[],"source":["# create metric\n","import numpy as np\n","\n","def corr(x, y):\n","  return np.corrcoef(x, y)[0][1]\n","\n","def corr_d(eval_pred):\n","  return {'pearson':corr(*eval_pred)}"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:12.265140Z","iopub.status.busy":"2023-04-10T15:35:12.264691Z","iopub.status.idle":"2023-04-10T15:35:20.647574Z","shell.execute_reply":"2023-04-10T15:35:20.646305Z","shell.execute_reply.started":"2023-04-10T15:35:12.265101Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["# Training our model\n","# To train a model in transformers we'll need this:\n","from transformers import TrainingArguments, Trainer"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:20.650349Z","iopub.status.busy":"2023-04-10T15:35:20.649363Z","iopub.status.idle":"2023-04-10T15:35:20.655672Z","shell.execute_reply":"2023-04-10T15:35:20.654435Z","shell.execute_reply.started":"2023-04-10T15:35:20.650302Z"},"trusted":true},"outputs":[],"source":["bs = 128\n","epochs = 4\n","lr = 8e-5"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:20.660426Z","iopub.status.busy":"2023-04-10T15:35:20.660073Z","iopub.status.idle":"2023-04-10T15:35:20.735991Z","shell.execute_reply":"2023-04-10T15:35:20.734953Z","shell.execute_reply.started":"2023-04-10T15:35:20.660396Z"},"trusted":true},"outputs":[],"source":["args = TrainingArguments(\n","    output_dir='outputs',\n","    learning_rate=lr,\n","    warmup_ratio=0.1,\n","    lr_scheduler_type='cosine',\n","    fp16=True, # if cuda, set it to True\n","    evaluation_strategy='epoch',\n","    per_device_train_batch_size=bs,\n","    per_device_eval_batch_size=bs*2,\n","    num_train_epochs=epochs,\n","    weight_decay=0.01,\n","    report_to='none'\n",")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:20.738182Z","iopub.status.busy":"2023-04-10T15:35:20.737428Z","iopub.status.idle":"2023-04-10T15:35:28.018210Z","shell.execute_reply":"2023-04-10T15:35:28.017160Z","shell.execute_reply.started":"2023-04-10T15:35:20.738142Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cfa105a1c614d23995418873b9f2faa","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Create model and trainer which combines the data and model together\n","model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=dds['train'],\n","    eval_dataset=dds['test'],\n","    tokenizer=tokz,\n","    compute_metrics=corr_d\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:35:28.020093Z","iopub.status.busy":"2023-04-10T15:35:28.019691Z","iopub.status.idle":"2023-04-10T15:39:58.959507Z","shell.execute_reply":"2023-04-10T15:39:58.958262Z","shell.execute_reply.started":"2023-04-10T15:35:28.020047Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [856/856 04:29, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Pearson</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.028622</td>\n","      <td>0.801928</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.024775</td>\n","      <td>0.826087</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.039000</td>\n","      <td>0.022813</td>\n","      <td>0.834306</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.039000</td>\n","      <td>0.022503</td>\n","      <td>0.835362</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=856, training_loss=0.028351240068952614, metrics={'train_runtime': 270.9169, 'train_samples_per_second': 403.873, 'train_steps_per_second': 3.16, 'total_flos': 716605488222960.0, 'train_loss': 0.028351240068952614, 'epoch': 4.0})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:46:25.192305Z","iopub.status.busy":"2023-04-10T15:46:25.191244Z","iopub.status.idle":"2023-04-10T15:46:25.233491Z","shell.execute_reply":"2023-04-10T15:46:25.232270Z","shell.execute_reply.started":"2023-04-10T15:46:25.192243Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6e2713b02f449de985236024865fd4a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Transform eval_df so tokens the model can take as input\n","eval_df['input'] = 'TEXT1: '+ eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n","eval_ds = Dataset.from_pandas(eval_df)\n","eval_ds = eval_ds.map(tok_func, batched=True)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-04-10T15:47:47.306040Z","iopub.status.busy":"2023-04-10T15:47:47.305437Z","iopub.status.idle":"2023-04-10T15:47:47.354755Z","shell.execute_reply":"2023-04-10T15:47:47.353667Z","shell.execute_reply.started":"2023-04-10T15:47:47.306000Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["array([[ 0.5546875 ],\n","       [ 0.68994141],\n","       [ 0.53369141],\n","       [ 0.31274414],\n","       [-0.01609802],\n","       [ 0.56689453],\n","       [ 0.53417969],\n","       [-0.02326965],\n","       [ 0.27514648],\n","       [ 1.0703125 ],\n","       [ 0.21069336],\n","       [ 0.27734375],\n","       [ 0.73779297],\n","       [ 0.86962891],\n","       [ 0.76171875],\n","       [ 0.56005859],\n","       [ 0.33618164],\n","       [ 0.01626587],\n","       [ 0.69726562],\n","       [ 0.37817383],\n","       [ 0.41870117],\n","       [ 0.22265625],\n","       [ 0.17773438],\n","       [ 0.24523926],\n","       [ 0.57666016],\n","       [-0.0383606 ],\n","       [-0.03845215],\n","       [-0.01753235],\n","       [-0.03546143],\n","       [ 0.61230469],\n","       [ 0.30175781],\n","       [ 0.01512909],\n","       [ 0.70898438],\n","       [ 0.54638672],\n","       [ 0.46679688],\n","       [ 0.26147461]])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["# Do prediction on eval_ds\n","pred = trainer.predict(eval_ds).predictions.astype(float)\n","pred.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Main takeaway\n","# input -> Transform(input) -> strings -> Tokenize(strings) -> numbers\n","# model(numbers) -> array of correlation (this is specific to this task)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"2a2361570f6453c7371f76f9a8a2b8edb0e00eb4650b517979698d06fb1123ae"}}},"nbformat":4,"nbformat_minor":4}
